# Safe Parallel Document Processing Implementation

## Description

Implement safe parallel processing for batch document uploads to improve performance while maintaining reliability and avoiding OpenAI API rate limits. The implementation will parallelize text extraction and preprocessing while keeping LightRAG inserts sequential to prevent knowledge graph corruption.

## Technical Requirements

Based on the current LightRAG upload flow analysis, implement controlled parallel processing with the following constraints:
- Parallelize text extraction (OCR, PDF parsing) - SAFE
- Parallelize validation and preprocessing - SAFE  
- Keep LightRAG inserts sequential - REQUIRED (shared state)
- Use conservative concurrency (2-3 documents max)
- Implement rate limiting (2-3 second delays)
- Add comprehensive monitoring and error handling

## Files to Modify

### Backend API Routes
- `backend/api/routes/documents.py`
  - Modify `upload_documents_stream()` function (line 160)
  - Replace sequential processing loop with controlled parallel batches
  - Add rate limiting between batches

### Backend Document Service
- `backend/domain/documents/service.py`
  - Enhance `upload_documents_batch()` method (line 532)
  - Add `process_documents_parallel_safe()` method
  - Implement rate limiter class for API call management

### Backend Infrastructure
- `backend/infrastructure/ai/rag_engine.py`
  - Add sequential insert queue for LightRAG operations
  - Ensure `insert()` method remains sequential (line 371)

## Implementation Algorithm

### Phase 1: Parallel Text Extraction
1. Process documents in controlled batches of 2-3 documents
2. Parallelize text extraction using existing `DocumentProcessor.extract_text()`
3. Apply rate limiting delays between batches (2-3 seconds)
4. Maintain progress streaming for each document

### Phase 2: Sequential LightRAG Processing
1. Queue extracted texts for sequential LightRAG processing
2. Process LightRAG inserts one at a time to prevent state corruption
3. Maintain progress updates during sequential processing
4. Handle errors gracefully with retry logic

### Phase 3: Rate Limiting Implementation
1. Create `RateLimiter` class with configurable RPM limits
2. Track API requests per minute for OpenAI calls
3. Implement exponential backoff for rate limit errors
4. Add monitoring for API usage patterns

## Key Constraints

- **LightRAG Sequential Requirement**: Must keep `rag_engine.insert()` calls sequential due to shared knowledge graph state
- **Conservative Concurrency**: Maximum 2-3 concurrent documents to avoid API rate limits
- **Rate Limiting**: 2-3 second delays between batches to respect OpenAI limits
- **Error Handling**: Comprehensive retry logic for failed operations
- **Progress Tracking**: Maintain real-time progress updates for UI

## Expected Performance Improvement

- **2-3x faster processing** for text extraction and preprocessing phases
- **Maintained reliability** through controlled concurrency
- **API rate limit compliance** through conservative limits and delays
- **No data corruption** through sequential LightRAG processing
