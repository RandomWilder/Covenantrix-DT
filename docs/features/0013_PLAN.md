# Feature 0013: OpenAI API Key Alignment

## Overview
Align OpenAI API key usage across the system to support both system keys (from .env in development) and user-provided keys (in distributed application). Currently, the system has UI for key management but the backend always uses .env keys and ignores user settings. The goal is to properly integrate the two flows, ensure proper key resolution, and enable toggling between modes for testing.

## Current State

**Working Components:**
- `.env` file loading via `backend/core/config.py` with `OPENAI_API_KEY`
- UI settings page at `covenantrix-desktop/src/features/settings/ApiKeysTab.tsx`
- UI onboarding flow at `covenantrix-desktop/src/features/onboarding/SettingsSetup.tsx`
- User settings storage at `backend/infrastructure/storage/user_settings_storage.py`
- Settings API routes at `backend/api/routes/settings.py`
- API key mode selection (default/custom) in settings schema

**Problem:**
- RAG engine initialization in `backend/main.py` always uses `settings.openai.api_key` from .env
- No mechanism to resolve keys from user settings when mode is "custom"
- User settings API keys are saved but never actually used by services
- No way to reload services when API keys change
- Cannot toggle between system and user keys for testing

## Technical Requirements

### 1. API Key Resolution Layer

**File: `backend/core/api_key_resolver.py` (NEW)**

Create a new module to handle API key resolution with the following logic:

```
Function: resolve_openai_key(user_settings: Optional[Dict], fallback_key: Optional[str]) -> Optional[str]
  - Check if user_settings exists and mode is "custom"
  - If custom mode, decrypt and return user_settings.api_keys.openai
  - Otherwise return fallback_key (from .env)
  - Return None if no key available

Function: resolve_cohere_key(user_settings: Optional[Dict], fallback_key: Optional[str]) -> Optional[str]
  - Same pattern as OpenAI

Function: resolve_google_key(user_settings: Optional[Dict], fallback_key: Optional[str]) -> Optional[str]
  - Same pattern as OpenAI
```

Must handle:
- Decryption of user-provided keys using `APIKeyManager`
- Proper fallback chain: user custom key → system .env key → None
- Logging of key source (system/user) without exposing key values

### 2. RAG Engine Initialization Update

**File: `backend/main.py`**

Update `lifespan()` function:
- After loading user_settings_dict (line 54), resolve the OpenAI key
- Call `resolve_openai_key(user_settings_dict, settings.openai.api_key)`
- Pass resolved key to `RAGEngine(api_key=resolved_key, ...)`
- Log which key source is being used ("Using OpenAI key from: [system/user]")

**File: `backend/infrastructure/ai/rag_engine.py`**

No changes needed - already accepts `api_key` parameter in `__init__`

### 3. Settings Apply Endpoint Enhancement

**File: `backend/api/routes/settings.py`**

Update `apply_settings()` endpoint (line 166):
- When API key mode changes or custom keys are updated, services need reloading
- Add logic to resolve keys using the new resolver
- Attempt to reinitialize RAG engine with new keys
- Update `restart_required` flag based on whether RAG reload succeeded
- If RAG engine reinit fails, set appropriate error response

Add new helper function in this file:
```
async def reload_rag_with_settings(settings_dict: Dict) -> bool
  - Resolve OpenAI key
  - If key available, create new RAG instance
  - Initialize it
  - Call set_rag_engine() to update global instance
  - Return success/failure
```

### 4. Key Validation Enhancement

**File: `backend/api/routes/settings.py`**

Update `validate_api_keys()` endpoint (line 85):
- Current validation only checks format (starts with "sk-", length > 20)
- Add actual OpenAI API test call using the provided key
- Create temporary OpenAI client with the test key
- Make a minimal API call (e.g., list models or embedding with short text)
- Return true validation result based on actual API response
- Catch and handle API errors gracefully

### 5. OpenAI Client Updates

**File: `backend/infrastructure/ai/openai_client.py`**

No structural changes needed - already accepts optional `api_key` parameter in `__init__`

Review all instantiation sites:
- Ensure they can receive resolved keys
- Analytics service creates OpenAI client - needs key resolution
- Any other direct OpenAI client usage should use resolved keys

**File: `backend/api/routes/analytics.py`**

Update `get_analytics_service()` dependency (line 25):
- Load user settings
- Resolve OpenAI key using the new resolver
- Pass resolved key when creating OpenAI client for LLM function

### 6. OCR Service Alignment

**File: `backend/core/dependencies.py`**

The `update_ocr_service_with_user_settings()` function (line 149) already implements the resolution pattern for Google Vision keys. Ensure consistency:
- Uses custom key if mode is "custom"
- Falls back to global settings
- This is the correct pattern - replicate for OpenAI keys

### 7. Testing Utilities

**File: `backend/api/routes/settings.py`**

Add new endpoint for development/testing:
```
POST /settings/test-mode
Request: { "mode": "system" | "user" }
Response: { "success": bool, "active_mode": str, "key_source": str }

- Temporarily override key resolution for testing
- Allow toggling between system and user keys without changing settings
- Only available when environment != "production"
```

### 8. Frontend Updates

**File: `covenantrix-desktop/src/contexts/SettingsContext.tsx`**

Update `applySettings()` method (line 111):
- After calling `window.electronAPI.applySettings()`
- Check if `response.restart_required` is true
- If true, show user notification that services are reloading
- Consider adding a loading state during reload

**File: `covenantrix-desktop/src/features/settings/ApiKeysTab.tsx`**

Update `validateKey()` method (line 39):
- Change from simulated validation to actual backend call
- Call `/settings/api-keys/validate` endpoint
- Show real validation status based on API response

**File: `covenantrix-desktop/src/features/onboarding/SettingsSetup.tsx`**

No changes needed - already validates via `validateApiKeys()` from settings context

## Files to Modify

**Backend:**
1. `backend/core/api_key_resolver.py` - NEW (Key resolution logic)
2. `backend/main.py` - Update lifespan RAG initialization
3. `backend/api/routes/settings.py` - Enhance apply and validation endpoints
4. `backend/api/routes/analytics.py` - Update analytics service dependency
5. `backend/core/dependencies.py` - Document OCR pattern as reference

**Frontend:**
1. `covenantrix-desktop/src/contexts/SettingsContext.tsx` - Handle reload notifications
2. `covenantrix-desktop/src/features/settings/ApiKeysTab.tsx` - Real validation

**Configuration:**
3. `backend/core/config.py` - Add comments documenting key resolution behavior

## Key Resolution Flow

1. **Startup (main.py):**
   ```
   Load .env → Load user_settings.json → Resolve keys → Initialize RAG
   ```

2. **Runtime (settings endpoint):**
   ```
   User updates keys → Validate keys → Save to user_settings.json → Apply settings → Reload RAG → Return success
   ```

3. **Resolution Priority:**
   ```
   User custom mode + key exists → Use user key
   Otherwise → Use system .env key
   Otherwise → None (service disabled)
   ```

## Validation Approach

**API Key Validation Steps:**
1. Check format (existing logic)
2. Make actual API call to OpenAI
3. Return success only if API responds successfully
4. Cache validation result to avoid repeated calls

## Testing Strategy

**Development Testing:**
1. Set `OPENAI_API_KEY` in `.env` file
2. Start application - should use system key
3. Via settings UI, switch to custom mode and enter different key
4. Apply settings - should reload RAG with user key
5. Verify logs show "Using OpenAI key from: user"
6. Switch back to default mode - should use system key again

**Distribution Testing:**
1. No `.env` file present
2. Launch application - should show onboarding
3. User enters their OpenAI key
4. Services should initialize with user key
5. Verify all AI features work (chat, document processing, analytics)

**Toggle Testing (Development Only):**
1. Use test-mode endpoint to switch between system/user
2. Verify each mode uses correct key source
3. Confirm services work in both modes

## Security Considerations

1. User custom keys are encrypted using `APIKeyManager` before storage
2. Keys are decrypted only when needed for API calls
3. Never log actual key values, only sources (system/user)
4. Validation endpoint doesn't store keys, only tests them
5. Test-mode endpoint disabled in production environment

## Logging

Add structured logging at key points:
- "Resolving OpenAI key: mode={mode}, source={source}"
- "RAG engine initialized with key from: {source}"
- "API key validation: type={type}, result={valid/invalid}"
- "Services reloaded with new key configuration"
- "Key resolution fallback: user key not available, using system key"

## Error Handling

1. If user key is invalid after saving, don't break system - fall back to system key
2. If both keys unavailable, disable AI features gracefully with clear user message
3. If RAG reload fails during apply, return error but keep old instance running
4. Validation failures should provide specific error messages (API error, format error, etc.)

